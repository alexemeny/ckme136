---
title: "CAPSTONE"
project: Housing Price Prediction
course: ckme136 XJO
instructor: Can Kavaklioglu 
output: html_document
---

OUTLINE with Sections

Exploratory data analysis

dimensons and type of variables
missing values
histogram to represent visual of continous variables or density plot
multivariate analysis like correlation (need data all numeric)
barplots for categorical variables

numeric
categorical
onehotencoding??

get ride of gr. lving above 4000
only normal sales
only houses that have basements..more uniform!!

new variables - total square feet, total bathrooms
most important categorical is neighbourhood : could bin on rich and poor levels?


IMPORTANT!! prepare data for modeling!! - IMPORTANT
1) drop high correlations
**look at correlation matrix again, and drop variables with high correlation.drop lowest corr to response variable!!

For instance: GarageCars and GarageArea have a correlation of 0.89. Of those two, I am dropping the variable with the lowest correlation with SalePrice (which is GarageArea with a SalePrice correlation of 0.62. GarageCars has a SalePrice correlation of 0.64).

dropVars <- c('YearRemodAdd', 'GarageYrBlt', 'GarageArea', 'GarageCond', 'TotalBsmtSF', 'TotalRmsAbvGrd', 'BsmtFinSF1')

all <- all[,!(names(all) %in% dropVars)]
2) remove outliers
3) split into numerical and categorical
4) skewness and normalize
5) one hot encoding categorical variables. 
The last step needed to ensure that all predictors are converted into numeric columns (which is required by most Machine Learning algorithms) is to ‘one-hot encode’ the categorical variables. This basically means that all (not ordinal) factor values are getting a seperate colums with 1s and 0s (1 basically means Yes/Present). To do this one-hot encoding, I am using the model.matrix() function.

DFdummies <- as.data.frame(model.matrix(~.-1, DFfactors))
dim(DFdummies)

Then remove one hot encoded wiht littel to no variance**Also taking out variables with less than 10 ‘ones’ in the train set.

fewOnes <- which(colSums(DFdummies[1:nrow(all[!is.na(all$SalePrice),]),])<10)
colnames(DFdummies[fewOnes])
6) skewness or log of saleprice??
7) compose train and test sets


MODELING CAN START!!!



----------------------------------------------------------------------------------
Introduction

2930 property sales in Ames, Iowa of residential homes between the years 2006 and 2012. 
Dataset contains a diverse mix of nominal, ordinal, continuous and discrete attributes.
Goal: best model to predict final sale prices of houses.

1)	Research Problem & Question: 
a.	Context of Problem – arbitrariness of housing price // what influeneces price negotiations?
b.	Theme – predictive analytics, challenge, opportunity to determine what has impact on final home price 
c.	State the problem: Research question - Which explanatory variables of residential homes can be used to predict sale price effectively?
d.	How propose to solve this problem?: Techniques


----------------------------------------------------------------------------------


----------------------------------------------------------------------------------
2)	Literature Review
a.	Summary of related papers – own words, some sort of flow and relationtion to topic
----------------------------------------------------------------------------------

#Leaving 2 spaces between ideas and 1 people writing and code boxes. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


----------------------------------------------------------------------------------
Installs and Libraries
----------------------------------------------------------------------------------

```{r}
#install.packages("PerformanceAnalytics") #A3
#install.packages("class") #A3
#install.packages("gmodels") #A3
#install.packages('FNN') #A3
#install.packages("ggplots2", dependencies = TRUE)  #visualtion of data *not working for R. V. 3.3.3
library("PerformanceAnalytics")  ##add tags for what each is used ofr
library(class)
library(gmodels)
library(FNN)


#install.packages("knitr")
#install.packages("plyr") # use revalue function
#install.packages("dplyr")
#install.packages('corrplot')
####install.packages('caret') #not working?
#install.packages('gridExtra')
#install.packages('scales')
#install.packages('Rmisc')
#install.packages('ggrepel')
install.packages('randomForest')
#install.packages('psych')
#install.packages('xgboost')

library(knitr)
#library(ggplot2)
library(plyr)
library(dplyr)
library(corrplot)
#library(caret)
library(gridExtra)
library(scales)
library(Rmisc)
library(ggrepel)
library(randomForest)
library(psych)
library(xgboost)
```

----------------------------------------------------------------------------------
3)	Dataset – how its only includes residential homes, Iowa …dimension, year range, year it was collected, 
a.	Source: Ames Housing Dataset, where found – kaggle
b.	Why good choice?
c.	Description of dataset
d.	Which attributes/variables will or will not use in analysis
e.	Descriptive Statistics – summary, overview, explanation of each variable.  (commentary)
f.	Manuel went through all variables and picked top 25, will compare to these at end to see if any relation?? Maybe
----------------------------------------------------------------------------------

Acquired off kaggle is a brief description of the data. For further info on how each attribute is measured: https://storage.googleapis.com/kaggle-competitions-data/kaggle/5407/205873/data_description.txt?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1553882575&Signature=T6oWIv13GvdjGf7WG6RZjZAbHfuRhVaC0km%2Be8cpOffhzu2DZ4JmrRocx9%2FlqRumuxW59sSG1iDzXFhhCco454%2BUmR%2Fxbu3uCHpD1dauiOSqWJSN1EnkHolkSzNCyhhSEwYCjda584OYUyRvYFMH1e1PzbW2XptAQmiML8K2e76Ml4PeOC8JT4Fv5X6uJ%2BwZ8MMzyuMwdcO9ojbYuXgXttmeJKmFmtsyrLVcW7PTg4EYbefKsi37eiH4b6eXPAIxrRyLr0%2F4m6Wtc9p9ATCNfeT24hvrZGb2w8iHCm%2Bt6gJXBvZeCX0PurdKabo%2FQbh8IX8y1%2BMmLp%2BDfNT2XIj7zA%3D%3D


SalePrice - the property's sale price in dollars. This is the target variable that you're trying to predict.
MSSubClass: The building class
MSZoning: The general zoning classification
LotFrontage: Linear feet of street connected to property
LotArea: Lot size in square feet
Street: Type of road access
Alley: Type of alley access
LotShape: General shape of property
LandContour: Flatness of the property
Utilities: Type of utilities available
LotConfig: Lot configuration
LandSlope: Slope of property
Neighborhood: Physical locations within Ames city limits
Condition1: Proximity to main road or railroad
Condition2: Proximity to main road or railroad (if a second is present)
BldgType: Type of dwelling
HouseStyle: Style of dwelling
OverallQual: Overall material and finish quality
OverallCond: Overall condition rating
YearBuilt: Original construction date
YearRemodAdd: Remodel date
RoofStyle: Type of roof
RoofMatl: Roof material
Exterior1st: Exterior covering on house
Exterior2nd: Exterior covering on house (if more than one material)
MasVnrType: Masonry veneer type
MasVnrArea: Masonry veneer area in square feet
ExterQual: Exterior material quality
ExterCond: Present condition of the material on the exterior
Foundation: Type of foundation
BsmtQual: Height of the basement
BsmtCond: General condition of the basement
BsmtExposure: Walkout or garden level basement walls
BsmtFinType1: Quality of basement finished area
BsmtFinSF1: Type 1 finished square feet
BsmtFinType2: Quality of second finished area (if present)
BsmtFinSF2: Type 2 finished square feet
BsmtUnfSF: Unfinished square feet of basement area
TotalBsmtSF: Total square feet of basement area
Heating: Type of heating
HeatingQC: Heating quality and condition
CentralAir: Central air conditioning
Electrical: Electrical system
1stFlrSF: First Floor square feet
2ndFlrSF: Second floor square feet
LowQualFinSF: Low quality finished square feet (all floors)
GrLivArea: Above grade (ground) living area square feet
BsmtFullBath: Basement full bathrooms
BsmtHalfBath: Basement half bathrooms
FullBath: Full bathrooms above grade
HalfBath: Half baths above grade
Bedroom: Number of bedrooms above basement level
Kitchen: Number of kitchens
KitchenQual: Kitchen quality
TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)
Functional: Home functionality rating
Fireplaces: Number of fireplaces
FireplaceQu: Fireplace quality
GarageType: Garage location
GarageYrBlt: Year garage was built
GarageFinish: Interior finish of the garage
GarageCars: Size of garage in car capacity
GarageArea: Size of garage in square feet
GarageQual: Garage quality
GarageCond: Garage condition
PavedDrive: Paved driveway
WoodDeckSF: Wood deck area in square feet
OpenPorchSF: Open porch area in square feet
EnclosedPorch: Enclosed porch area in square feet
3SsnPorch: Three season porch area in square feet
ScreenPorch: Screen porch area in square feet
PoolArea: Pool area in square feet
PoolQC: Pool quality
Fence: Fence quality
MiscFeature: Miscellaneous feature not covered in other categories
MiscVal: $Value of miscellaneous feature
MoSold: Month Sold
YrSold: Year Sold
SaleType: Type of sale
SaleCondition: Condition of sale
SalePrice: Selling Price of the House



The dataset is related to house prices of residential homes in Ames, Iowa. I came across it in Kaggle's competition section. For more info:
https://www.kaggle.com/c/house-prices-advanced-regression-techniques

```{r}
ames <- read.csv("~/Desktop/ames.csv", header = TRUE, sep = ',', stringsAsFactors = F)  #stringsAsFactors = F add this to read in as character strings instead of factors (even though many variables are ordinal), so can clean and engineer better.  
head(ames) #see it loaded correctly
View(ames) #see as dataframe

```


```{r}
dim(ames) 
#see that there are 2930 rows and 82 variables.

str(ames[,c(1:9, 82)])
#show structure of first 9 variables and then target variable (Sale Price)

```


```{r}

#found csv file that had ames data alreaady combined, but alternatively could bind the train and test datasets provided off kaggle. Link to download full: https://www.openintro.org/stat/data/?data=ames

ames$Order <- NULL
#dont need order variable, no actual order

uniqueID <- ames$PID
ames$PID <- NULL
#keep ID's as vector, but going to remove from dataset.

dim(ames)
#now are 79 explanatory variables and 1 response variable. still 2930 rows.
#these 80 variables focus on the quality and quanitity of physical attributes of the houses. Basically what a potential home buyer would want to know about a property.
#example questions are: size of lot, square feet? when built? number of bedrooms, bathrooms, garage, pool, finished basement? etc. 

```

####### use %% for new idea of topic ######

1. Check data characteristics. Is there missing data? 
%%Check for missing data! 

In checking for complete rows of data it is surprising to get the result that all 2930 observations have missing data. Upon further analysis of the variables can see that NA which is representing missing fields does not necessarily mean missing data. Can replace appropriate NA's with None or 0 instead to show doesnt have this element. Example being Alley, says NA when House does not have one connecting. For other results that may actually be missing can use mean or median values of remaining. 

```{r}

summary(ames)
#There are 20 continuous variables related to area dimensions such as total square footage as well as individual measurements of basement, main living area and porch square footages. 
#There are 14 discrete variables describing number of items in the house such as bedrooms, garage capacity, kitchens and bathrooms etc. 
#There are 46 categorical variables both nominal and ordinal. Have a range of 2 classes for variable Street (gravel or paved) all the way to 28 classes for variable Neighbourhoods. 
#the summary statistics also give idea of range and/or frequency for each variable. 

sum(is.na(ames))
#are 13960 NA fields, need to look further into this. 
sum(is.null(ames))
#0 null fields

missing_values <- ames[!complete.cases(ames),]
nrow(missing_values)
#see number of rows that have missing values, is 2930. Meaning all of them so something is going on, will explore further. 


#????replace NA's in the data for each row with correct values. 
```

```{r}

#continued missing values 
#check which columns have NA's and how many total. Are 25, as seen below which need to be fixed this is a good starting point.

NAcolumns <- names(which(sapply(ames, anyNA)))
NAcolumns
length(NAcolumns)


```


Besides making sure that the NAs are taken care off, I have also converted character variables into ordinal integers if there is clear ordinality, or into factors if levels are categories without ordinality. I will convert these factors into numeric later on by using one-hot encoding (using the model.matrix function).

---
Get rid of NA values, convert character variables to intergers if ordinality or to factors if not. Afterwards will work on conversion of these factors (ones with no apparent order to there levels) into numeric variables thorugh one-hot encoding. Usse the model.matrix function.

Goal to go through all columns and convert into numeric or factors so can be converted afterwards. 
Will replace NA with 0 in numeric fields and 'None' for character variables where appropriate. 

Did each column one by one horizontally across no order, and put result of that variable into proper section to keep track.

---------------------------------------
Numeric variables replace NA's.

Lot.Frontage
```{r}
#potentially all 0's or could actualy be missing values will find out??
#for all 490 NA's in Lot.Frontage vairbale represent no lot.frontage, so replacing NA's with interger value 0.

ames$Lot.Frontage[is.na(ames$Lot.Frontage)] <- 0
sum(is.na(ames$Lot.Frontage))
#no NA's in Lot.Frontage
summary(ames$Lot.Frontage)


```

Garage Cars and Garage Area 
```{r}

#same 1 entry is NA for both these variables and has no garage. 

sum(is.na(ames$Garage.Cars))
#1 NA value

ames$Garage.Cars[is.na(ames$Garage.Cars)] <- 0
#replace Na with most common being 2. 

sum(is.na(ames$Garage.Area))
#1 NA Value
ames$Garage.Area[is.na(ames$Garage.Area)] <- 0

#table(ames$Garage.Cars)
#table(ames$Garage.Cars)

#which(is.na(ames$Garage.Area))
#line 2237 so could check out.

```

Garage  YrBuilt
```{r}

sum(is.na(ames$Garage.Yr.Blt))
#159 NA values with missing years represent properties with no garage built. 

ames$Garage.Yr.Blt[is.na(ames$Garage.Yr.Blt)] <- 0 

#since this variable seems irrelevant as  years span well outside range of sale years. going to replace NA values with 0 to represent no garage built and move on. Can look at later if necessary. 

table(ames$Garage.Yr.Blt)

```

Basement Variables
```{r}

#NA's for 6 variables below refer to no basement present.

sum(is.na(ames$BsmtFin.SF.1))
sum(is.na(ames$BsmtFin.SF.2))
sum(is.na(ames$Bsmt.Unf.SF))
sum(is.na(ames$Total.Bsmt.SF))
#these 4 variables have 1 NA value each

ames$BsmtFin.SF.1[is.na(ames$BsmtFin.SF.1)] <-0
ames$BsmtFin.SF.2[is.na(ames$BsmtFin.SF.2)] <-0
ames$Bsmt.Unf.SF[is.na(ames$Bsmt.Unf.SF)] <-0
ames$Total.Bsmt.SF[is.na(ames$Total.Bsmt.SF)] <-0

sum(is.na(ames$Bsmt.Full.Bath))
sum(is.na(ames$Bsmt.Half.Bath))
# these 2 have 2 NA values each. 

ames$Bsmt.Full.Bath[is.na(ames$Bsmt.Full.Bath)] <-0
table(ames$Bsmt.Full.Bath)

#1709 have no basement bathroom, 1181 have 1 full basement bathoom. 

ames$Bsmt.Half.Bath[is.na(ames$Bsmt.Half.Bath)] <-0
table(ames$Bsmt.Half.Bath) 

#2755 observations have no half basement bathroom. 


#removed remaining NA's from these basement variables so are all numeric now. 

```

Masonary Area and Type
```{r}

sum(is.na(ames$Mas.Vnr.Type))
#0 NA's

sum(is.na(ames$Mas.Vnr.Area))
#23 Na's

ames$Mas.Vnr.Area[is.na(ames$Mas.Vnr.Area)] <-0
#converted NA's to 0 as no area for no masonary area.

```

Kitchen Variables
```{r}
sum(is.na(ames$Kitchen.Qual))
ames$Kitchen.Qual<-as.integer(revalue(ames$Kitchen.Qual, Ratings))
table(ames$Kitchen.Qual)

sum(is.na(ames$Kitchen.AbvGr))
table(ames$Kitchen.AbvGr)

```

Utilities and Functional
```{r}
sum(is.na(ames$Utilities))
#no NA values
table(ames$Utilities)
#almost 100% are public utilities so variable is not going to be helpful in making a prediction and can get rid of it. 

ames$Utilities <- NULL
#now 79 explanatory variables
```

-------------------------------------------------
Character Variables with ordinal properties to integers. (Both with and withou NA's)

Lot.Shape
```{r}
#revalue function from package plyr
#no NA values, but has order with regular best, followed by IR1 (slightly irregular), IR2 (moderately irregular) and worst being IR3 (irregular). 

View(ames)

ames$Lot.Shape <- as.integer(revalue(ames$Lot.Shape, c('IR3'=0, 'IR2'=1, 'IR1'=2, 'Reg'=3)))

#now 4 is the best and 0 is the worst for lot shape regularity. 
```

PoolQuality
```{r}

#this variable has level ex for excellent, gd for good, ta for typical/average, fa for fair and then NA for no pool so need to replace NA with no pool. 
#has highest number of NA's. May be explained as a pool can be seen as a luxury feature.

Ratings <- c('None' = 0, 'Po' = 1, 'Fa' = 2, 'TA' = 3, 'Gd' = 4, 'Ex' = 5)
#create vector with quality ratings as this is seen across multiple variables. 


ames$Pool.QC[is.na(ames$Pool.QC)] <- 'None'
ames$Pool.QC <- as.integer(revalue(ames$Pool.QC, Ratings))
table(ames$Pool.QC)

#Now 5 is excellent all the way to 0 is for None. 
```

Fireplace Quality
```{r}

sum(is.na(ames$Fireplace.Qu))
#there are 1422 NA values in Fireplace.Qu

ames$Fireplace.Qu[is.na(ames$Fireplace.Qu)] <- 'None'
ames$Fireplace.Qu <- as.integer(revalue(ames$Fireplace.Qu, Ratings))
#same quality rating scale as pool quality.
table(ames$Fireplace.Qu)

#5 is for excellent adn 0 is for none. 

table(ames$Fireplaces)
#range from 0 to 4. most 0 or 1, 1422 or 1274. 
```

Garage Quality
```{r}

ames$Garage.Qual[is.na(ames$Garage.Qual)] <- 'None'
ames$Garage.Qual<-as.integer(revalue(ames$Garage.Qual, Ratings))
table(ames$Garage.Qual)

#5 is for excellent adn 0 is for none.
#3 for TA meaning typical or average is most popular by big proportion. 

```

Garage.Condition
```{r}

ames$Garage.Cond[is.na(ames$Garage.Cond)] <- 'None'
ames$Garage.Cond <- as.integer(revalue(ames$Garage.Cond, Ratings))
table(ames$Garage.Cond)

#3 for TA meaning typical or average is most popular by big proportion. 
```

Garage Finish
```{r}
# is ordinal with order of finished, rough finish, unfinished and no garage. 

ames$Garage.Finish[is.na(ames$Garage.Finish)] <- 'None'
#replace NA's with none for no garage. 

Finish <- c('None'=0, 'Unf'=1, 'RFn'=2, 'Fin'=3)
#create vector with ratings.

ames$Garage.Finish <- as.integer(revalue(ames$Garage.Finish, Finish))
table(ames$Garage.Finish)

#now Garage.Finish have 3 for finished to 1 unfinished garage and 0 no garage. 
#unfinished most popular, with rough second.

```

Basement Variables
```{r}

sum(is.na(ames$Bsmt.Qual))
sum(is.na(ames$Bsmt.Cond))
sum(is.na(ames$Bsmt.Exposure))
sum(is.na(ames$BsmtFin.Type.1))
sum(is.na(ames$BsmtFin.Type.2))
#these 5 variables have 79 NA values each
#factorize using ratings vector /hot encode

ames$Bsmt.Qual[is.na(ames$Bsmt.Qual)] <- 'None'
ames$Bsmt.Qual<-as.integer(revalue(ames$Bsmt.Qual, Ratings))
table(ames$Bsmt.Qual)

#most common Basement Quality is between 3 and 4, so Typical and Good. 

ames$Bsmt.Cond[is.na(ames$Bsmt.Cond)] <- 'None'
ames$Bsmt.Cond<-as.integer(revalue(ames$Bsmt.Cond, Ratings))
table(ames$Bsmt.Cond)

#most common is Basement Condition is 3 for typical/average.

ames$Bsmt.Exposure[is.na(ames$Bsmt.Exposure)] <- 'None'
Exposure <- c('None'=0, 'No'=1, 'Mn'=2, 'Av'=3, 'Gd'=4)
# create vector for exposure

ames$Bsmt.Exposure<-as.integer(revalue(ames$Bsmt.Exposure, Exposure))
table(ames$Bsmt.Exposure)

#most common is Basement exposure is no exposure.

ames$BsmtFin.Type.1[is.na(ames$BsmtFin.Type.1)] <- 'None'
FinishType <- c('None'=0, 'Unf'=1, 'LwQ'=2, 'Rec'=3, 'BLQ'=4, 'ALQ'=5, 'GLQ'=6)
#create vector
ames$BsmtFin.Type.1 <-as.integer(revalue(ames$BsmtFin.Type.1, FinishType))
table(ames$BsmtFin.Type.1)

sum(is.na(ames$BsmtFin.Type.1))

#spread out. 

ames$BsmtFin.Type.2[is.na(ames$BsmtFin.Type.2)] <- 'None'
FinishType <- c('None'=0, 'Unf'=1, 'LwQ'=2, 'Rec'=3, 'BLQ'=4, 'ALQ'=5, 'GLQ'=6)
#create vector
ames$BsmtFin.Type.2 <-as.integer(revalue(ames$BsmtFin.Type.2, FinishType))
table(ames$BsmtFin.Type.2)

#most common is unfinished. 
```

Functional
```{r}
sum(is.na(ames$Functional))
#no NA values

#ordinal so convert to numeric with typical being best at 7 and salvage worst at 0. 

scale <- c('Sal'=0, 'Sev'=1, 'Maj2'=2, 'Maj1'=3, 'Mod'=4, 'Min2'=5, 'Min1'=6, 'Typ'=7)
#create vector
ames$Functional <- as.integer(revalue(ames$Functional, scale))
table(ames$Functional)

#vast majority are typical with score 7 so no not very relevant variable for prediction. 
```

Exterior Variables Quality and Condition
```{r}

#No NA's can convert using ratings of qualties vector

ames$Exter.Qual<-as.integer(revalue(ames$Exter.Qual, Ratings))
table(ames$Exter.Qual)

#3 is most common for typical or average quality

ames$Exter.Cond<-as.integer(revalue(ames$Exter.Cond, Ratings))
table(ames$Exter.Cond)

#3 is most common with typical or average quality of exterior condition. (2549).
```

---------------------------------------
Character variables to factors becasue no ordinality

Alley
```{r}

sum(is.na(ames$Alley))
#there are 2732 NA values in the Alley variable. They represent no alley so will replace NA with 'NONE' and turn into a factor because categories are not ordinal.

ames$Alley[is.na(ames$Alley)] <- 'None'
ames$Alley <- as.factor(ames$Alley)
table(ames$Alley)

#now Alley is a factor with 3 levels.
```

Lot.Configuration
```{r}

#no NA values, levels include inside lot, corner lot, cul-de-sac, frontage on 2 sides of property and frontage on 3 so no apparent ordinality. Convert to factor. 

ames$Lot.Config <- as.factor(ames$Lot.Config)
table(ames$Lot.Config)

#factor with 5 levels now.

```

MS.Zoning
```{r}

#MS.Zoning variable has no NA values and is not ordinal so turn to factor.

ames$MS.Zoning <- as.factor(ames$MS.Zoning)
table(ames$MS.Zoning)

#MS.Zoning is now a factor with 7 levels. 

```

Misc.Features
```{r}

sum(is.na(ames$Misc.Feature))
#there are 2824 Null values for Miscellaneous Feature variable. Convert to factor as no ordinality.

ames$Misc.Feature[is.na(ames$Misc.Feature)] <- 'None'
#None means no miscellaneous features for this property.
ames$Misc.Feature <- as.factor(ames$Misc.Feature)
table(ames$Misc.Feature)

#High proportion of homes dont have these features which makes this variable almost irrelevant. Only 1 has an elevator or a tennis court so these features cannot significantly provide insight into a final sale price even if we'd assume they'd increase the price. 

#now Misc.Feature is a factor with 6 levels.
```

Fence
```{r}

sum(is.na(ames$Fence))
#There are 2358 NA values for this variable a high amount meaning no fence, so will replace with 'none'.
#Some order but not enough so convert to factor.

ames$Fence[is.na(ames$Fence)] <- 'None'
ames$Fence <- as.factor(ames$Fence)
table(ames$Fence)

#now Fence is a factor with 4 levels. 
```

GarageType
```{r}

ames$Garage.Type[is.na(ames$Garage.Type)] <- 'None'
ames$Garage.Type <- as.factor(ames$Garage.Type)
table(ames$Garage.Type)

#now is factor with 7 levels
```

Electrical
```{r}

sum(is.na(ames$Electrical))
ames$Electrical <- as.factor(ames$Electrical)
table(ames$Electrical)

#factor with 5 levels
```

Exterior Variables 1st and 2nd
```{r}
ames$Exterior.1st <- as.factor(ames$Exterior.1st)
#table(ames$Exterior.1st)

#factor with 16 levels. categories that are not ordinal.

ames$Exterior.2nd <- as.factor(ames$Exterior.2nd)
#table(ames$Exterior.2nd)

#factor with 16 levels. categories that are not ordinal.

```

Sale Type
```{r}
ames$Sale.Type <- as.factor(ames$Sale.Type)
table(ames$Sale.Type)

# factor with 10 levels.

```

Sale Condition
```{r}

#values are categorical, no NA's

ames$Sale.Condition <- as.factor(ames$Sale.Condition)
table(ames$Sale.Condition)

#2413 sales are normal, large proportion and thinking to just use this.

#to not complicate results going to focus on variable Sale.Condition that is 'normal'. The other 5 classes here are 1) Abnormal such as trade, foreclosure, or short sale 2) Adjoing land purchase, 3)allocation meaning two linked properities, such as condo and garage unit 4)sale between family members and 5) partial when new home was not complete yet. So in summary a normal sale would represent a more common typical transaction of a home. 

#Eliminate any bonus or discounts potentially present in abnormal sales that is beyond scope of data.

COME BACK TO THIS!!

```

---
Convert Numeric Variable into factors!

MS.SubClass
```{r}

#type of property in sale through reference number.
#convert to factor

ames$MS.SubClass <- as.factor(ames$MS.SubClass)
table(ames$MS.SubClass)

#now MS.SubClass is a factor with 16 levels
```

Month Sold
```{r}

ames$Mo.Sold <- as.factor(ames$Mo.Sold)
table(ames$Mo.Sold)

#now Mo.Sold is factor with 12 levels. (January to December)
#Could indicate seasonality. Summer months have high totals and begining and end of year seem to be slower months.

```

Year Sold
```{r}

ames$Yr.Sold <- as.factor(ames$Yr.Sold)
table(ames$Yr.Sold)

#Yr. Sold variable is a factor now with 5 levels representing the years 2006 to 2010. 

```


done converting all to numeric now can do a littel feature engineering before preparing data for model. 
----


```{r}
#check NA's left and can see 0 NA's left so missing values are dealt with. 

sum(is.na(ames))

# check structure to make sure no character variables left. Have some so will continue converting to factors
str(ames)

Remaining_CharVar <- names(ames[,sapply(ames, is.character)])
Remaining_CharVar

length(Remaining_CharVar)
#16 character variables left to factorize.
```

Remainingg 16 Character Varaibles convert to ordinal integers or to factors
```{r}
#1 - Foundation
ames$Foundation <- as.factor(ames$Foundation)
table(ames$Foundation)
#factor with 6 levels, most common CBlock and PConc

#2 - Heating
ames$Heating <- as.factor(ames$Heating)
table(ames$Heating)
#factor with 6 levels, most common GasA

#3 - Heating Quality
ames$Heating.QC <-as.integer(revalue(ames$Heating.QC, Ratings))
table(ames$Heating.QC)
#most common is 5 for excellent heating quality. (1495)

#4 - Central Air
ames$Central.Air<-as.integer(revalue(ames$Central.Air, c('N'=0, 'Y'=1)))
table(ames$Central.Air)
#yes 2734 of the time so majority have central air.

#5 - RoofStyle
ames$Roof.Style <- as.factor(ames$Roof.Style)
table(ames$Roof.Style)
#factor with 6 levels, most common Gable (2321)

#6 - Roof Material
ames$Roof.Matl <- as.factor(ames$Roof.Matl)
table(ames$Roof.Matl)
#factor with 8 levels, most common CompShg (2887)

#7 - Land Contour
ames$Land.Contour <- as.factor(ames$Land.Contour)
table(ames$Land.Contour)
# factor with 4 levels, most common Lvl (2633)

#8 - Land Slope
ames$Land.Slope<-as.integer(revalue(ames$Land.Slope, c('Sev'=0, 'Mod'=1, 'Gtl'=2)))
table(ames$Land.Slope)
# Gt1 is most common, 2789

#9 - Building Type
ames$Bldg.Type <- as.factor(ames$Bldg.Type)
table(ames$Bldg.Type)
#factor with 5 levels, most common 1Fam 2425

#10 - House Style
ames$House.Style <- as.factor(ames$House.Style)
table(ames$House.Style)
#factor with 8 levels, most common 1 story 1481

#11 - Neighborhood
ames$Neighborhood <- as.factor(ames$Neighborhood)
table(ames$Neighborhood)
#factor with 28 levels, 

#12 - Condition1
ames$Condition.1 <- as.factor(ames$Condition.1)
table(ames$Condition.1)
#factor with 9 levels, common is Norm with 2522

#13 - Condition2
ames$Condition.2 <- as.factor(ames$Condition.2)
table(ames$Condition.2)
#factor with 8 levels, Norm most 2900

#14 - Street
ames$Street<-as.integer(revalue(ames$Street, c('Grvl'=0, 'Pave'=1)))
table(ames$Street)
#Paved most commmon 2918 of the time.

#15 -Paved Drive
ames$Paved.Drive<-as.integer(revalue(ames$Paved.Drive, c('N'=0, 'P'=1, 'Y'=2)))
table(ames$Paved.Drive)
#Yes paved drive most common 2652

#16 - Mas.Var.Type
ames$Mas.Vnr.Type <- as.factor(ames$Mas.Vnr.Type)
table(ames$Mas.Vnr.Type)
#most common is none at 1752, factor with 6 levels.

#all ran smoothly and now no character variables left all are numeric or factor. For the factor will convert with one hot encoding afterwards. 
```

```{r}

str(ames)

Numeric_variables <- which(sapply(ames, is.numeric))
Factor_Variables <- which(sapply(ames, is.factor))
length(Numeric_variables)
length(Factor_Variables)
#have 2930 observations of 79 variables with no NA values. 
#Have 54 numeric variables and have 25 factors. This includes SalePrice. 
```

Quick look at correlation again since more numeric variables with at least 0.5 absolute to SalePrice. 
```{r}

Numeric_variables <- which(sapply(ames, is.numeric)) #vector with numeric variables
length(Numeric_variables)
#there are 37 numeric variables

frame_numericV <- ames[,Numeric_variables]
cor_numericV <- cor(frame_numericV, use = "pairwise.complete.obs") 
#correlation of all 37 numeric variables

Ranked_cor_numericV <- as.matrix(sort(cor_numericV[,'SalePrice'], decreasing = TRUE))
#gives correlations in decreasing strength

top_cor_numericV <- names(which(apply(Ranked_cor_numericV, 1, function(x) abs(x)>0.5))) 
#top correlations above 0.5 or -0.5. 

cor_numericV <- cor_numericV[top_cor_numericV,top_cor_numericV]

corrplot.mixed(cor_numericV, tl.col = 'blue', tl.pos = 'lt')


#16 numeric variables above 0.5 correlation with SalePrice. 
```

---------------------
----------------------
Feature Engineering

Total Square Feet
```{r}

#add new variable that includes the total ground living area and total basement square footage. 
ames$Total.Sq.Feet <- ames$Gr.Liv.Area + ames$Total.Bsmt.SF

cor(ames$SalePrice, ames$Total.Sq.Feet, use= "pairwise.complete.obs")
#correlation of new attribute is strong at 0.79.

plot(ames$SalePrice ~ ames$Total.Sq.Feet)
#can see some outliers

#rows with total square feet over 6000 are 6 cases: 1499, 1761, 1768, 1773, 2181, 2182

cor(ames$SalePrice[-c(1499, 1761, 1768, 1773, 2181, 2182)], ames$Total.Sq.Feet[-c(1499, 1761, 1768, 1773, 2181, 2182)], use= "pairwise.complete.obs")
#remove outliers by excluding total square footage over 6000 because over 99% of the observations are below this threshold. (2924/2930 = 0.998). This gets rid of those properties with abnormally large square footages compared to rest of the observations. 

#By removing these outliers correlation goes up to 0.82. A 4 percent increase by removing 6 cases. 

```

Total Bathrooms
```{r}

#combine the 4 bathroom variables, awarding half baths as 0.5 and full as 1.

ames$Total.Bathrooms <- ames$Full.Bath + (ames$Half.Bath*0.5) + ames$Bsmt.Full.Bath + (ames$Bsmt.Half.Bath*0.5)

cor(ames$SalePrice, ames$Total.Bathrooms, use= "pairwise.complete.obs")
#gives a positive correlation of 0.63. 

plot(ames$Total.Bathrooms, ames$SalePrice)
#shows more total bathrooms has a relationship with higher sale price. 
```



```{r}



```


-------------------------
Prepare Data For Modeling

1. Remove Highly Correlated Variables
```{r}




```

2. Remove Outliers
```{r}



```

3. Split into Numeric and Factor dataframes and scale //Normalize
```{r}



```

4. 
```{r}



```

5. Compose Train and Test Sets
```{r}



```

*use number of fireplaces after one-hot encoding
```{r}
table(ames$Fireplaces)
```


Condition of Sale: Normal or Abnormal..stick with just normal!!

```{r}

#to not complicate results going to focus on variable Sale.Condition that is 'normal'. The other 5 classes here are 1) Abnormal such as trade, foreclosure, or short sale 2) Adjoing land purchase, 3)allocation meaning two linked properities, such as condo and garage unit 4)sale between family members and 5) partial when new home was not complete yet. So in summary a normal sale would represent a more common typical transaction of a home. Eliminate any bonus or discounts potentially present in abnormal sales that is beyond scope of data. 

```


IMPORTANT:Explore Response Variable
ALSO 2. What is the correlation between the attributes other than SalePrice? 
```{r}

summary(data$SalePrice)
hist(data$SalePrice)
#quick histogram shows that the sale prices are right skewed. A logicial explanation for this is that fewer people can afford more expensive homes. This is something to keep in mind and potentially look at houses under the value of 400,000. **
```

1st look at numeric variables relation to sale price. 
```{r}

numericV <- which(sapply(data, is.numeric)) #vector with numeric variables
length(numericV)
#there are 37 numeric variables

frame_numericV <- data[,numericV]
cor_numericV <- cor(frame_numericV, use = "pairwise.complete.obs") 
#correlation of all 37 numeric variables

Ranked_cor_numericV <- as.matrix(sort(cor_numericV[,'SalePrice'], decreasing = TRUE))
#gives correlations in decreasing strength

top_cor_numericV <- names(which(apply(Ranked_cor_numericV, 1, function(x) abs(x)>0.5))) 
#top correlations above 0.5 or -0.5. 

cor_numericV <- cor_numericV[top_cor_numericV,top_cor_numericV]

corrplot.mixed(cor_numericV, tl.col = 'blue', tl.pos = 'lt')
#in visual can see numeric attributes with highest correlation to SalePrice as Overall Quality, Ground Living Area and Garage Cars. 
```

```{r}
par(mfrow=c(2,2))
#use to plot 4 main correlations from above

plot(data$Overall.Qual, data$SalePrice)
plot(data$Garage.Area, data$Garage.Cars)
plot(data$X1st.Flr.SF, data$Total.Bsmt.SF)
plot(data$Garage.Yr.Blt, data$Year.Built)

#this shows a visual of directionality. All strong positive correlations above 0.8. Collinearity is an issue from multiple variables provide similiar degree of predictive value. 
```

```{r}
chart.Correlation(cor_numericV, histogram=TRUE, pch=19)
#installed "PerformanceAnalytics" package to use chart.Correlation
#Another way to visual the correlation between variables.

?? doesnt really fit!

```

```{r}
#Look at strong correlations with SalePrice. 

boxplot(data$SalePrice~data$Overall.Qual)
boxplot(data$SalePrice~data$Gr.Liv.Area)
boxplot(data$SalePrice~data$Garage.Cars)

#low score could explain low price so be dangerous to remove outliers here
# can think remove gr living area above 4000, just outliers of really big homes proportionate to rest of houses. 
#fix up with header, x and y label and ranges...main point is to show outliers or 
```


```{r}
Need all of data to be numberic first!!! Then look at correlation. 


```

```{r}

```



```{r}

```

Remove outliers...under 4000??


*Total square footage (new vairable of ground and basement) to salprice..plot this fitted line
Scatterplot of Sale Price versus Total Home Area by Sale Condition (Ames Data)
```{r}

```

In selecting observations...could go further and eliminate homes without a basement!! or just look at one story homes..could also draw a simple random sample from remaining normal sales to build a final set. 
```{r}

```


```{r}

```

The nominal variable was created by recoding the number of fireplaces
into a simple Yes/No (1/0) dummy variable.
***neighborhood variable into their models by converting it to a set of dummy (indicator) variables. (one hot encoding)
```{r}

```

IMPORTANT 5. Normalize the data set. 
```{r}

#need data to all be numeric 1st!! this is top priority. 

normalize <- function(x) {return ((x - min(x)) / (max(x) - min(x))) }

wine_normalized <- as.data.frame(lapply(white_wine[,1:11], normalize))
summary(wine_normalized)

summary(white_wine)
#original data set for comparision.


```

IMPORTANT 6. Divide the data to training and testing groups. 
```{r}

#once normalized. 
set.seed(100)
wine_new <- sample(nrow(wine_normalized), floor(nrow(wine_normalized)*0.7))
wine_train <- wine_normalized[wine_new,]
wine_test <- wine_normalized[-wine_new,]
ratings_train <- white_wine$ratings[wine_new]
ratings_test <- white_wine$ratings[-wine_new]

#test to make sure all data was divided into 2 groups. And this is true.
nrow(wine_normalized) == (nrow(wine_train) + nrow(wine_test))
#split data into training and test by 70/30.

NOW NOW NOW
#can use algorithm to predict, have a train and test set. 


```


8. Evaluate the model performance. 

```{r}

accuracy, percision, recall

```





----------------------------------------------------------------------------------
4)	Data Preparation and Analysis
a.	Load correctly
b.	Format, not duplicates, missing values, fields are uniform, dimensions
c.	Clean, mention summary and descriptive statistics as way to  draw insights from data…assist me in building a better expertise of the domain of features so I can for effectively look for patterns and relationships. 1st take. (can include, histogram, boplot, pairwise scatterplot to observe correlation, distribution of variables, skewness and potential outliers)
d.	Look at target variable of final sale price. For continuous variables look at min, max, mean, median, quartiles. Also since target variable of final sale price is continuous want to look at continuous house prices instead of individual house price ranges. 
e.	Transform data or normalize (ONE HOT ENCODING): In order to run models on data will need to transform it. Don't want string types to train machine learning models so need values to be numerical. Ways includes converting discrete to continuous variables (ex. One-hot-encoding, convert and create more columns). Another way involves creating dummy variables for categorical variables, such as assigning values of 0 or 1 to show if a 
----------------------------------------------------------------------------------

```{r}

```


```{r}

```


----------------------------------------------------------------------------------
5)	Feature selection:
a.	Optimize parameters by selecting and analyzing / build model (this case regression)
b.	Normalization.  (Xnew=(X-Xmin)/(Xmax-Xmin). Scale. 
c.	Use creativity to build new features from the input data. An example is total square footage (TOTAL BSMT SF + GR LIV AREA). Look for positive variables that might add value such as being near a park or negative variables that reduce value such as being near a railroad. 
d.	Compare feature selection from manual chosen vs algorithm selection.
----------------------------------------------------------------------------------


create feature: There are 4 bathroom variables. Individually, these variables are not very important. However, I assume that I if I add them up into one predictor, this predictor is likely to become a strong one.

“A half-bath, also known as a powder room or guest bath, has only two of the four main bathroom components-typically a toilet and sink.” Consequently, I will also count the half bathrooms as half.
all$TotBathrooms <- all$FullBath + (all$HalfBath*0.5) + all$BsmtFullBath + (all$BsmtHalfBath*0.5)



```{r}

```





```{r}

```

----------------------------------------------------------------------------------
6)	Train and Test Algorithms
a.	Regression
b.	Random forest
c.	CART
d.	SVM support vector machine?
e.	Ensemble learning? Xgboost (use this for next section to try and improve results or random forest too 
f.	Lasso or ridge regression
g.	Neural network? Something new to try?? Thought was really interesting

•	Split into test and train sets so can use k-fold validation to compare models. (80/20, train, test, 10 fold
----------------------------------------------------------------------------------

```{r}

```



```{r}

```

----------------------------------------------------------------------------------
7)	Evaluate
a.	Choose performance metrics.
b.	Avoid overfitting
c.	GO BACK part: PCA. feature engineering and using the statistical procedure of principle component analysis to reduce dimensionality & improve prediction results. Such as accuracy. 
d.	To evaluate performance can look at plot of actual vs predicted values, see a fitted regression line,  r squared statistical measure to see the level of variability the model explains, (A r^2 of 1 would indicate the regression predictions fit the data perfectly, I’d be looking for a low P value and high r^2 value combination to see if my regression model has significant variables). Can look at mean absolute error also. 
----------------------------------------------------------------------------------

```{r}

```



```{r}

```



----------------------------------------------------------------------------------
8)	Results
a.	Look at statistical tests on results. 
b.	Precision, recall etc. 
c.	Look into reasons behind variables with most predictive significance. Discussion and application to housing market. Relate to relevancy and applicability to for other cities housing parameters. Features that are missing such as backyard size, economy of closest major city, proximity to public transportations, schools, etc. 

CONCLUSION - summary of what did and major points findings
----------------------------------------------------------------------------------



## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
